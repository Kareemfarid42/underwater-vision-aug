{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535955c-733c-43c5-838c-56f9c260a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "def Rotate_Image(input_image: np.ndarray, angle_degrees: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    angle_degrees = np.clip(angle_degrees, -30, 30)\n",
    "    \n",
    "    height, width = input_image.shape[:2]\n",
    "    center = (width / 2, height / 2)\n",
    "    \n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle_degrees, scale=1.0)\n",
    "    \n",
    "    rotated_image = cv2.warpAffine(\n",
    "        input_image,\n",
    "        rotation_matrix,\n",
    "        (width, height),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_REFLECT\n",
    "    )\n",
    "    \n",
    "    return rotated_image\n",
    "\n",
    "def Flip_Horizontal(input_image: np.ndarray) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    return cv2.flip(input_image, 1)\n",
    "\n",
    "def Flip_Vertical(input_image: np.ndarray) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    return cv2.flip(input_image, 0)\n",
    "\n",
    "def Random_Crop(input_image: np.ndarray, crop_height: int, crop_width: int) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    height, width = input_image.shape[:2]\n",
    "    \n",
    "    if crop_height > height or crop_width > width:\n",
    "        return input_image\n",
    "    \n",
    "    max_y = height - crop_height\n",
    "    max_x = width - crop_width\n",
    "    \n",
    "    y_start = np.random.randint(0, max_y + 1) if max_y > 0 else 0\n",
    "    x_start = np.random.randint(0, max_x + 1) if max_x > 0 else 0\n",
    "    \n",
    "    cropped_image = input_image[y_start:y_start + crop_height, x_start:x_start + crop_width]\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "def Resize_Image(input_image: np.ndarray, target_height: int, target_width: int) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    resized_image = cv2.resize(\n",
    "        input_image,\n",
    "        (target_width, target_height),\n",
    "        interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def Mosaic_Augmentation(image_batch_list: List[np.ndarray], \n",
    "                        target_height: int, target_width: int) -> np.ndarray:\n",
    "    if len(image_batch_list) != 4:\n",
    "        raise ValueError(f\"Mosaic requires exactly 4 images, got {len(image_batch_list)}\")\n",
    "    \n",
    "    for i, img in enumerate(image_batch_list):\n",
    "        if img is None or img.size == 0:\n",
    "            raise ValueError(f\"Image at index {i} is empty or None\")\n",
    "    \n",
    "    half_height = target_height // 2\n",
    "    half_width = target_width // 2\n",
    "    \n",
    "    resized_images = []\n",
    "    for img in image_batch_list:\n",
    "        resized = Resize_Image(img, half_height, half_width)\n",
    "        resized_images.append(resized)\n",
    "    \n",
    "    if len(resized_images[0].shape) == 3:\n",
    "        channels = resized_images[0].shape[2]\n",
    "        mosaic = np.zeros((target_height, target_width, channels), dtype=resized_images[0].dtype)\n",
    "    else:\n",
    "        mosaic = np.zeros((target_height, target_width), dtype=resized_images[0].dtype)\n",
    "    \n",
    "    mosaic[0:half_height, 0:half_width] = resized_images[0]\n",
    "    mosaic[0:half_height, half_width:target_width] = resized_images[1]\n",
    "    mosaic[half_height:target_height, 0:half_width] = resized_images[2]\n",
    "    mosaic[half_height:target_height, half_width:target_width] = resized_images[3]\n",
    "    \n",
    "    return mosaic\n",
    "\n",
    "def Mixup_Augmentation(image_1: np.ndarray, image_2: np.ndarray, \n",
    "                       mixup_alpha: float) -> np.ndarray:\n",
    "    if image_1 is None or image_1.size == 0:\n",
    "        raise ValueError(\"image_1 is empty or None\")\n",
    "    if image_2 is None or image_2.size == 0:\n",
    "        raise ValueError(\"image_2 is empty or None\")\n",
    "    \n",
    "    mixup_alpha = np.clip(mixup_alpha, 0.2, 0.4)\n",
    "    \n",
    "    if image_1.shape != image_2.shape:\n",
    "        target_height, target_width = image_1.shape[:2]\n",
    "        image_2 = cv2.resize(image_2, (target_width, target_height), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    img1_float = image_1.astype(np.float32)\n",
    "    img2_float = image_2.astype(np.float32)\n",
    "    \n",
    "    blended = mixup_alpha * img1_float + (1 - mixup_alpha) * img2_float\n",
    "    blended = np.clip(blended, 0, 255)\n",
    "    \n",
    "    return blended.astype(image_1.dtype)\n",
    "\n",
    "def Ripple_Distortion(input_image: np.ndarray, amplitude: float, frequency: float) -> Optional[np.ndarray]:\n",
    "    if input_image is None: return None\n",
    "    h, w = input_image.shape[:2]\n",
    "    \n",
    "    frequency = max(frequency, 0.1) \n",
    "    wavelength = w / frequency\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    cx, cy = w // 2, h // 2\n",
    "    \n",
    "    distance = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "    \n",
    "    displacement = amplitude * np.sin(distance / wavelength * 2 * np.pi)\n",
    "    \n",
    "    map_x = (x + displacement).astype(np.float32)\n",
    "    map_y = (y + displacement).astype(np.float32)\n",
    "    \n",
    "    distorted = cv2.remap(\n",
    "        input_image, \n",
    "        map_x, \n",
    "        map_y, \n",
    "        interpolation=cv2.INTER_LINEAR, \n",
    "        borderMode=cv2.BORDER_REFLECT\n",
    "    )\n",
    "    \n",
    "    return distorted\n",
    "\n",
    "def Wave_Distortion(input_image: np.ndarray, amplitude: float, frequency: float, \n",
    "                   wave_direction: str = 'horizontal') -> Optional[np.ndarray]:\n",
    "    if input_image is None: return None\n",
    "    h, w = input_image.shape[:2]\n",
    "    \n",
    "    frequency = max(frequency, 0.1)\n",
    "    wavelength = w / frequency\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "\n",
    "    if wave_direction == 'horizontal':\n",
    "        map_x = x + amplitude * np.sin(2 * np.pi * y / wavelength)\n",
    "        map_y = y\n",
    "    else:\n",
    "        map_x = x\n",
    "        map_y = y + amplitude * np.sin(2 * np.pi * x / wavelength)\n",
    "\n",
    "    map_x = map_x.astype(np.float32)\n",
    "    map_y = map_y.astype(np.float32)\n",
    "\n",
    "    distorted = cv2.remap(\n",
    "        input_image, \n",
    "        map_x, \n",
    "        map_y, \n",
    "        interpolation=cv2.INTER_LINEAR, \n",
    "        borderMode=cv2.BORDER_REFLECT\n",
    "    )\n",
    "    return distorted\n",
    "\n",
    "def Bubbles_Overlay(input_image: np.ndarray, bubble_count: int = 10) -> Optional[np.ndarray]:\n",
    "    if input_image is None: return None\n",
    "    \n",
    "    result = input_image.copy()\n",
    "    h, w = result.shape[:2]\n",
    "    \n",
    "    for _ in range(bubble_count):\n",
    "        cx = np.random.randint(0, w)\n",
    "        cy = np.random.randint(0, h)\n",
    "        radius = np.random.randint(5, 20)\n",
    "        \n",
    "        cv2.circle(result, (cx, cy), radius, (255, 255, 255), 1)\n",
    "        cv2.circle(result, (cx - radius//3, cy - radius//3), 1, (255, 255, 255), 1)\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def Caustic_Overlay(input_image: np.ndarray, blend_strength: float = 0.2) -> Optional[np.ndarray]:\n",
    "    if input_image is None: return None\n",
    "    \n",
    "    img_float = input_image.astype(np.float32) / 255.0\n",
    "    h, w = img_float.shape[:2]\n",
    "\n",
    "    scale = int(min(h, w) * 0.03) \n",
    "    scale = max(scale, 5)     \n",
    "    \n",
    "    noise = np.random.rand(h, w).astype(np.float32)\n",
    "    noise = cv2.GaussianBlur(noise, (0, 0), scale)\n",
    "    \n",
    "    gx = cv2.Sobel(noise, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(noise, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    \n",
    "    caustic_pattern = np.sqrt(gx**2 + gy**2)\n",
    "    \n",
    "    caustic_pattern = cv2.normalize(caustic_pattern, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    caustic_pattern = np.power(caustic_pattern, 3) \n",
    "    \n",
    "    if len(input_image.shape) == 3:\n",
    "        caustic_pattern = np.repeat(caustic_pattern[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    result = img_float + (caustic_pattern * blend_strength)\n",
    "    \n",
    "    result = np.clip(result, 0, 1)\n",
    "    return (result * 255).astype(np.uint8)\n",
    "\n",
    "def Debris_Overlay(input_image: np.ndarray, debris_count: int = 50) -> Optional[np.ndarray]:\n",
    "    if input_image is None: return None\n",
    "        \n",
    "    h, w = input_image.shape[:2]\n",
    "    debris_layer = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for _ in range(debris_count):\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        \n",
    "        color_intensity = np.random.randint(100, 255)\n",
    "        color = (color_intensity, color_intensity, color_intensity)\n",
    "        \n",
    "        size = np.random.randint(1, 4)\n",
    "        cv2.circle(debris_layer, (x, y), size, color, -1)\n",
    "\n",
    "    debris_layer = cv2.GaussianBlur(debris_layer, (3, 3), 0)\n",
    "    \n",
    "    result = cv2.add(input_image, debris_layer)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def Color_Jitter_Brightness(input_image: np.ndarray, brightness_factor: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    brightness_factor = np.clip(brightness_factor, 0.8, 1.2)\n",
    "    \n",
    "    brightened = input_image.astype(np.float32) * brightness_factor\n",
    "    brightened = np.clip(brightened, 0, 255)\n",
    "    \n",
    "    return brightened.astype(np.uint8)\n",
    "\n",
    "def Color_Jitter_Contrast(input_image: np.ndarray, contrast_factor: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    contrast_factor = np.clip(contrast_factor, 0.8, 1.2)\n",
    "    \n",
    "    img_float = input_image.astype(np.float32)\n",
    "    mean = np.mean(img_float, axis=(0, 1), keepdims=True)\n",
    "    \n",
    "    contrasted = (img_float - mean) * contrast_factor + mean\n",
    "    contrasted = np.clip(contrasted, 0, 255)\n",
    "    \n",
    "    return contrasted.astype(np.uint8)\n",
    "\n",
    "def Color_Jitter_Saturation(input_image: np.ndarray, saturation_factor: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    if len(input_image.shape) != 3 or input_image.shape[2] != 3:\n",
    "        raise ValueError(\"Input image must be a 3-channel BGR image\")\n",
    "    \n",
    "    saturation_factor = np.clip(saturation_factor, 0.5, 2.0)\n",
    "    \n",
    "    hsv = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    \n",
    "    hsv[:, :, 1] = hsv[:, :, 1] * saturation_factor\n",
    "    hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)\n",
    "    \n",
    "    hsv = hsv.astype(np.uint8)\n",
    "    saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return saturated\n",
    "\n",
    "def Color_Jitter_Hue(input_image: np.ndarray, hue_shift_value: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    if len(input_image.shape) != 3 or input_image.shape[2] != 3:\n",
    "        raise ValueError(\"Input image must be a 3-channel BGR image\")\n",
    "    \n",
    "    hue_shift_value = np.clip(hue_shift_value, -10, 10)\n",
    "    \n",
    "    hsv = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    \n",
    "    hsv[:, :, 0] = (hsv[:, :, 0] + hue_shift_value) % 180\n",
    "    \n",
    "    hsv = hsv.astype(np.uint8)\n",
    "    hue_shifted = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return hue_shifted\n",
    "\n",
    "def Attenuate_Channel(input_image: np.ndarray, channel_index: int, \n",
    "                      attenuation_factor: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    if len(input_image.shape) != 3 or input_image.shape[2] != 3:\n",
    "        raise ValueError(\"Input image must be a 3-channel BGR image\")\n",
    "    \n",
    "    if channel_index not in [0, 1, 2]:\n",
    "        raise ValueError(\"channel_index must be 0 (Blue), 1 (Green), or 2 (Red)\")\n",
    "    \n",
    "    attenuation_factor = np.clip(attenuation_factor, 0.6, 0.9)\n",
    "    \n",
    "    attenuated = input_image.astype(np.float32).copy()\n",
    "    attenuated[:, :, channel_index] = attenuated[:, :, channel_index] * attenuation_factor\n",
    "    attenuated = np.clip(attenuated, 0, 255)\n",
    "    \n",
    "    return attenuated.astype(np.uint8)\n",
    "\n",
    "def Adjust_Gamma(input_image: np.ndarray, gamma_value: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    gamma_value = np.clip(gamma_value, 0.8, 1.2)\n",
    "    \n",
    "    inv_gamma = 1.0 / gamma_value\n",
    "    lut = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(np.uint8)\n",
    "    \n",
    "    gamma_corrected = cv2.LUT(input_image, lut)\n",
    "    \n",
    "    return gamma_corrected\n",
    "\n",
    "def Add_Haze(input_image: np.ndarray, haze_intensity: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    haze_intensity = np.clip(haze_intensity, 0.1, 0.3)\n",
    "    \n",
    "    img_float = input_image.astype(np.float32)\n",
    "    white = np.ones_like(img_float) * 255\n",
    "    \n",
    "    hazed = img_float * (1 - haze_intensity) + white * haze_intensity\n",
    "    hazed = np.clip(hazed, 0, 255)\n",
    "    \n",
    "    return hazed.astype(np.uint8)\n",
    "\n",
    "def Add_Fog(input_image: np.ndarray, scattering_coefficient: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    scattering_coefficient = np.clip(scattering_coefficient, 0.6, 2.5)\n",
    "    \n",
    "    height, width = input_image.shape[:2]\n",
    "    \n",
    "    depth_map = np.linspace(0, 1, width, dtype=np.float32)\n",
    "    depth_map = np.tile(depth_map, (height, 1))\n",
    "    \n",
    "    transmission = np.exp(-scattering_coefficient * depth_map)\n",
    "    \n",
    "    if len(input_image.shape) == 3:\n",
    "        transmission = transmission[:, :, np.newaxis]\n",
    "    \n",
    "    atmospheric_light = 200\n",
    "    \n",
    "    img_float = input_image.astype(np.float32)\n",
    "    fogged = img_float * transmission + atmospheric_light * (1 - transmission)\n",
    "    fogged = np.clip(fogged, 0, 255)\n",
    "    \n",
    "    return fogged.astype(np.uint8)\n",
    "\n",
    "def Underwater_Turbidity(input_image: np.ndarray, red_attn: float, \n",
    "                        green_attn: float, blue_attn: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    if len(input_image.shape) != 3 or input_image.shape[2] != 3:\n",
    "        raise ValueError(\"Input image must be a 3-channel BGR image\")\n",
    "    \n",
    "    red_attn = np.clip(red_attn, 0.4, 0.7)\n",
    "    green_attn = np.clip(green_attn, 0.7, 0.9)\n",
    "    blue_attn = np.clip(blue_attn, 0.6, 0.9)\n",
    "    \n",
    "    turbid = input_image.astype(np.float32).copy()\n",
    "    \n",
    "    turbid[:, :, 0] = turbid[:, :, 0] * blue_attn\n",
    "    turbid[:, :, 1] = turbid[:, :, 1] * green_attn\n",
    "    turbid[:, :, 2] = turbid[:, :, 2] * red_attn\n",
    "    \n",
    "    turbid = np.clip(turbid, 0, 255)\n",
    "    \n",
    "    return turbid.astype(np.uint8)\n",
    "\n",
    "def Scattering_Blur(input_image: np.ndarray, sigma_value: float) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    sigma_value = np.clip(sigma_value, 0.5, 2.0)\n",
    "    \n",
    "    kernel_size = int(2 * np.ceil(3 * sigma_value) + 1)\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(input_image, (kernel_size, kernel_size), sigmaX=sigma_value)\n",
    "    \n",
    "    return blurred\n",
    "\n",
    "def Multi_Color_Space_Fusion(input_image: np.ndarray) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "\n",
    "    img_hsv = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    img_lab = cv2.cvtColor(input_image, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "\n",
    "    v_channel = img_hsv[:, :, 2]\n",
    "    l_channel = img_lab[:, :, 0]\n",
    "\n",
    "    fused_v = (0.5 * v_channel) + (0.5 * l_channel)\n",
    "    \n",
    "    img_hsv[:, :, 2] = fused_v\n",
    "    img_hsv = np.clip(img_hsv, 0, 255).astype(np.uint8)\n",
    "\n",
    "    fused_image = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return fused_image\n",
    "\n",
    "def Channel_wise_Multi_scale(input_image: np.ndarray) -> np.ndarray:\n",
    "    if input_image is None or input_image.size == 0:\n",
    "        raise ValueError(\"Input image is empty or None\")\n",
    "    \n",
    "    img_float = input_image.astype(np.float32)\n",
    "    \n",
    "    scales = [1.0, 2.0, 4.0]\n",
    "    weights = [0.5, 0.3, 0.2] \n",
    "    \n",
    "    detail_accumulator = np.zeros_like(img_float)\n",
    "    \n",
    "    for sigma, weight in zip(scales, weights):\n",
    "        ksize = int(2 * np.ceil(3 * sigma) + 1)\n",
    "        blurred = cv2.GaussianBlur(img_float, (ksize, ksize), sigma)\n",
    "        \n",
    "        detail = img_float - blurred\n",
    "        \n",
    "        detail_accumulator += detail * weight\n",
    "        \n",
    "    sharpened = img_float + detail_accumulator\n",
    "    \n",
    "    sharpened = np.clip(sharpened, 0, 255)\n",
    "    return sharpened.astype(np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
